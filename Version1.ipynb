{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Approval Rate: 37.36%\n",
      "Average Credit Score: 571\n",
      "Average Annual Income: $6896\n",
      "Average Loan Amount: $24965\n",
      "Average Total Debt-to-Income Ratio: 5.26\n",
      "Average Interest Rate: 27.68%\n",
      "\n",
      "Focused synthetic data saved to 'focused_synthetic_loan_data.csv'\n",
      "\n",
      "Total number of features (including label): 37\n",
      "\n",
      "Features:\n",
      "- ApplicationDate\n",
      "- Age\n",
      "- AnnualIncome\n",
      "- CreditScore\n",
      "- EmploymentStatus\n",
      "- EducationLevel\n",
      "- Experience\n",
      "- LoanAmount\n",
      "- LoanDuration\n",
      "- MaritalStatus\n",
      "- NumberOfDependents\n",
      "- HomeOwnershipStatus\n",
      "- MonthlyDebtPayments\n",
      "- CreditCardUtilizationRate\n",
      "- NumberOfOpenCreditLines\n",
      "- NumberOfCreditInquiries\n",
      "- DebtToIncomeRatio\n",
      "- BankruptcyHistory\n",
      "- LoanPurpose\n",
      "- PreviousLoanDefaults\n",
      "- PaymentHistory\n",
      "- LengthOfCreditHistory\n",
      "- SavingsAccountBalance\n",
      "- CheckingAccountBalance\n",
      "- TotalAssets\n",
      "- TotalLiabilities\n",
      "- MonthlyIncome\n",
      "- UtilityBillsPaymentHistory\n",
      "- JobTenure\n",
      "- NetWorth\n",
      "- BaseInterestRate\n",
      "- InterestRate\n",
      "- MonthlyLoanPayment\n",
      "- TotalDebtToIncomeRatio\n",
      "- LoanApproved\n",
      "- RiskScore\n",
      "-  vRiskLevel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "# Number of samples\n",
    "num_samples = 40000\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_correlated_features(num_samples):\n",
    "    # Generate base features\n",
    "    age = np.random.normal(40, 12, num_samples).clip(18, 80).astype(int)\n",
    "    experience = (age - 18 - np.random.normal(4, 2, num_samples).clip(0)).clip(0).astype(int)\n",
    "    education_level = np.random.choice(['High School', 'Associate', 'Bachelor', 'Master', 'Doctorate'], num_samples, p=[0.3, 0.2, 0.3, 0.15, 0.05])\n",
    "    \n",
    "    # Education affects income and credit score\n",
    "    edu_impact = {'High School': 0, 'Associate': 0.1, 'Bachelor': 0.2, 'Master': 0.3, 'Doctorate': 0.4}\n",
    "    edu_factor = np.array([edu_impact[level] for level in education_level])\n",
    "    \n",
    "    # Generate correlated income, credit score, and employment status\n",
    "    base_income = np.random.lognormal(10.5, 0.6, num_samples) * (1 + edu_factor) * (1 + experience / 100)\n",
    "    income_noise = np.random.normal(0, 0.1, num_samples)\n",
    "\n",
    "    low_income_max = 190 * 12  # Convert monthly $190 to annual income\n",
    "    middle_income_min = 190 * 12\n",
    "    middle_income_max = 500 * 12\n",
    "    high_income_min = 500 * 12\n",
    "\n",
    "    # Define proportions for each income range\n",
    "    low_income_ratio = 0.3  # Average of 30-40%\n",
    "    middle_income_ratio = 0.5  # Average of 40-50%\n",
    "    high_income_ratio = 0.20  # Average of 10-20%\n",
    "\n",
    "    # Calculate the number of samples for each range\n",
    "    low_income_count = int(num_samples * low_income_ratio)\n",
    "    middle_income_count = int(num_samples * middle_income_ratio)\n",
    "    high_income_count = num_samples - low_income_count - middle_income_count  # Remaining samples\n",
    "\n",
    "    # Generate income values for each range\n",
    "    low_income = np.random.uniform(1500, low_income_max, low_income_count).astype(int)  # $1500/year is the minimum\n",
    "    middle_income = np.random.uniform(middle_income_min, middle_income_max, middle_income_count).astype(int)\n",
    "    high_income = np.random.uniform(high_income_min, 36000, high_income_count).astype(int)  # $36,000/year is the maximum\n",
    "\n",
    "    # Combine income groups and shuffle for randomness\n",
    "    annual_income = np.concatenate([low_income, middle_income, high_income])\n",
    "    np.random.shuffle(annual_income)\n",
    "\n",
    "\n",
    "    credit_score_base = 300 + 300 * stats.beta.rvs(5, 1.5, size=num_samples)\n",
    "    credit_score = (credit_score_base + edu_factor * 100 + experience * 1.5 + income_noise * 100).clip(300, 850).astype(int)\n",
    "    \n",
    "    employment_status_probs = np.column_stack([\n",
    "        0.9 - edu_factor * 0.3,  # Employed\n",
    "        0.05 + edu_factor * 0.2,  # Self-Employed\n",
    "        0.05 + edu_factor * 0.1   # Unemployed\n",
    "    ])\n",
    "    employment_status = np.array(['Employed', 'Self-Employed', 'Unemployed'])[np.argmax(np.random.random(num_samples)[:, np.newaxis] < employment_status_probs.cumsum(axis=1), axis=1)]\n",
    "    \n",
    "    return age, experience, education_level, annual_income, credit_score, employment_status\n",
    "\n",
    "# def generate_random_dates(num_samples, start_date=\"2018-01-01\", end_date=\"2023-12-31\"):\n",
    "#     \"\"\"\n",
    "#     Generate random dates within a specified range.\n",
    "\n",
    "#     Args:\n",
    "#         num_samples (int): Number of random dates to generate.\n",
    "#         start_date (str): Start of the date range (inclusive).\n",
    "#         end_date (str): End of the date range (inclusive).\n",
    "\n",
    "#     Returns:\n",
    "#         list: List of random datetime objects.\n",
    "#     \"\"\"\n",
    "#     start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "#     end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "#     date_range = (end_date - start_date).days\n",
    "    \n",
    "#     random_dates = [\n",
    "#         start_date + timedelta(days=random.randint(0, date_range))\n",
    "#         for _ in range(num_samples)\n",
    "#     ]\n",
    "#     return random_dates\n",
    "\n",
    "def generate_time_based_features(num_samples):\n",
    "    start_date = datetime(2018, 1, 1)\n",
    "    dates = [start_date + timedelta(days=i) for i in range(num_samples)]\n",
    "    return dates\n",
    "\n",
    "age, experience, education_level, annual_income, credit_score, employment_status = generate_correlated_features(num_samples)\n",
    "application_dates = generate_time_based_features(num_samples)\n",
    "\n",
    "data = {\n",
    "    'ApplicationDate': application_dates,\n",
    "    'Age': age,\n",
    "    'AnnualIncome': annual_income,\n",
    "    'CreditScore': credit_score,\n",
    "    'EmploymentStatus': employment_status,\n",
    "    'EducationLevel': education_level,\n",
    "    'Experience': experience,\n",
    "    'LoanAmount': np.random.lognormal(10, 0.5, num_samples).astype(int),\n",
    "    'LoanDuration': np.random.choice([12, 24, 36, 48, 60, 72, 84, 96, 108, 120], num_samples, p=[0.05, 0.1, 0.2, 0.2, 0.2, 0.1, 0.05, 0.05, 0.025, 0.025]),\n",
    "    'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced', 'Widowed'], num_samples, p=[0.3, 0.5, 0.15, 0.05]),\n",
    "    'NumberOfDependents': np.random.choice([0, 1, 2, 3, 4, 5], num_samples, p=[0.3, 0.25, 0.2, 0.15, 0.07, 0.03]),\n",
    "    'HomeOwnershipStatus': np.random.choice(['Own', 'Rent', 'Mortgage', 'Other'], num_samples, p=[0.2, 0.3, 0.4, 0.1]),\n",
    "    'MonthlyDebtPayments': np.random.lognormal(6, 0.5, num_samples).astype(int),\n",
    "    'CreditCardUtilizationRate': np.random.beta(2, 5, num_samples),\n",
    "    'NumberOfOpenCreditLines': np.random.poisson(3, num_samples).clip(0, 15).astype(int),\n",
    "    'NumberOfCreditInquiries': np.random.poisson(1, num_samples).clip(0, 10).astype(int),\n",
    "    'DebtToIncomeRatio': np.random.beta(2, 5, num_samples),\n",
    "    'BankruptcyHistory': np.random.choice([0, 1], num_samples, p=[0.95, 0.05]),\n",
    "    'LoanPurpose': np.random.choice(['Home', 'Auto', 'Education', 'Debt Consolidation', 'Other'], num_samples, p=[0.3, 0.2, 0.15, 0.25, 0.1]),\n",
    "    'PreviousLoanDefaults': np.random.choice([0, 1], num_samples, p=[0.9, 0.1]),\n",
    "    'PaymentHistory': np.random.poisson(24, num_samples).clip(0, 60).astype(int),\n",
    "    'LengthOfCreditHistory': np.random.randint(1, 30, num_samples),\n",
    "    'SavingsAccountBalance': np.random.lognormal(8, 1, num_samples).astype(int),\n",
    "    'CheckingAccountBalance': np.random.lognormal(7, 1, num_samples).astype(int),\n",
    "    'TotalAssets': np.random.lognormal(11, 1, num_samples).astype(int),\n",
    "    'TotalLiabilities': np.random.lognormal(10, 1, num_samples).astype(int),\n",
    "    'MonthlyIncome': annual_income / 12,\n",
    "    'UtilityBillsPaymentHistory': np.random.beta(8, 2, num_samples),\n",
    "    'JobTenure': np.random.poisson(5, num_samples).clip(0, 40).astype(int),\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure TotalAssets is always greater than or equal to the sum of SavingsAccountBalance and CheckingAccountBalance\n",
    "df['TotalAssets'] = np.maximum(df['TotalAssets'], df['SavingsAccountBalance'] + df['CheckingAccountBalance'])\n",
    "\n",
    "# Add more complex derived features\n",
    "min_net_worth = 1000  # Set a minimum net worth\n",
    "df['NetWorth'] = np.maximum(df['TotalAssets'] - df['TotalLiabilities'], min_net_worth)\n",
    "\n",
    "# More realistic interest rate based on credit score, loan amount, and loan duration\n",
    "df['BaseInterestRate'] = 0.03 + (850 - df['CreditScore']) / 2000 + df['LoanAmount'] / 400000 + df['LoanDuration'] / 1200\n",
    "df['InterestRate'] = df['BaseInterestRate'] * (1 + np.random.normal(0, 0.1, num_samples)).clip(0.8, 1.2)\n",
    "\n",
    "df['MonthlyLoanPayment'] = (df['LoanAmount'] * (df['InterestRate']/12)) / (1 - (1 + df['InterestRate']/12)**(-df['LoanDuration']))\n",
    "df['TotalDebtToIncomeRatio'] = (df['MonthlyDebtPayments'] + df['MonthlyLoanPayment']) / df['MonthlyIncome']\n",
    "\n",
    "# Create a more complex loan approval rule\n",
    "def loan_approval_rule(row):\n",
    "    score = 0\n",
    "    score += (row['CreditScore'] - 600) / 250  # Credit score factor\n",
    "    score += (24000 - row['AnnualIncome']) / 24000  # Income factor\n",
    "    score += (row['TotalDebtToIncomeRatio'] - 0.4) * 2  # DTI factor\n",
    "    score += (row['LoanAmount'] - 1800) / 9000  # Loan amount factor\n",
    "    score += (row['InterestRate'] - 0.05) * 10  # Interest rate factor\n",
    "    score += 0.5 if row['BankruptcyHistory'] == 1 else 0  # Bankruptcy penalty\n",
    "    score += 0.3 if row['PreviousLoanDefaults'] == 1 else 0  # Previous default penalty\n",
    "    score += 0.2 if row['EmploymentStatus'] == 'Unemployed' else 0  # Employment status factor\n",
    "    score -= 0.1 if row['HomeOwnershipStatus'] in ['Own', 'Mortgage'] else 0  # Home ownership factor\n",
    "    score -= row['PaymentHistory'] / 120  # Payment history factor\n",
    "    score -= row['LengthOfCreditHistory'] / 60  # Length of credit history factor\n",
    "    score -= row['NetWorth'] / 5000  # Net worth factor\n",
    "    \n",
    "    # Age factor (slight preference for middle-aged applicants)\n",
    "    score += abs(row['Age'] - 40) / 100\n",
    "    \n",
    "    # Experience factor\n",
    "    score -= row['Experience'] / 200\n",
    "    \n",
    "    # Education factor\n",
    "    edu_score = {'High School': 0.2, 'Associate': 0.1, 'Bachelor': 0, 'Master': -0.1, 'Doctorate': -0.2}\n",
    "    score += edu_score[row['EducationLevel']]\n",
    "    \n",
    "    # Seasonal factor (higher approval rates in spring/summer)\n",
    "    month = row['ApplicationDate'].month\n",
    "    score -= 0.1 if 3 <= month <= 8 else 0\n",
    "    \n",
    "    # Random factor to add some unpredictability\n",
    "    score += np.random.normal(0, 0.1)\n",
    "    \n",
    "    return 1 if score < 1 else 0  # Adjust this threshold to change overall approval rate\n",
    "\n",
    "df['LoanApproved'] = df.apply(loan_approval_rule, axis=1)\n",
    "\n",
    "# Add some noise and outliers\n",
    "noise_mask = np.random.choice([True, False], num_samples, p=[0.01, 0.99])\n",
    "df.loc[noise_mask, 'AnnualIncome'] = (df.loc[noise_mask, 'AnnualIncome'] * np.random.uniform(1.5, 2.0, noise_mask.sum())).astype(int)\n",
    "\n",
    "low_net_worth_mask = df['NetWorth'] == min_net_worth\n",
    "df.loc[low_net_worth_mask, 'NetWorth'] += np.random.randint(0, 1000, size=low_net_worth_mask.sum())\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Loan Approval Rate: {df['LoanApproved'].mean():.2%}\")\n",
    "print(f\"Average Credit Score: {df['CreditScore'].mean():.0f}\")\n",
    "print(f\"Average Annual Income: ${df['AnnualIncome'].mean():.0f}\")\n",
    "print(f\"Average Loan Amount: ${df['LoanAmount'].mean():.0f}\")\n",
    "print(f\"Average Total Debt-to-Income Ratio: {df['TotalDebtToIncomeRatio'].mean():.2f}\")\n",
    "print(f\"Average Interest Rate: {df['InterestRate'].mean():.2%}\")\n",
    "\n",
    "def assign_credit_score_risk(credit_score):\n",
    "    if credit_score >= 750: return 1\n",
    "    elif 700 <= credit_score < 750: return 2\n",
    "    elif 650 <= credit_score < 700: return 3\n",
    "    elif 600 <= credit_score < 650: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_dti_risk(dti):\n",
    "    if dti < 0.20: return 1\n",
    "    elif 0.20 <= dti < 0.30: return 2\n",
    "    elif 0.30 <= dti < 0.40: return 3\n",
    "    elif 0.40 <= dti < 0.50: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_payment_history_risk(payment_history):\n",
    "    if payment_history >= 99: return 1\n",
    "    elif 97 <= payment_history < 99: return 2\n",
    "    elif 95 <= payment_history < 97: return 3\n",
    "    elif 90 <= payment_history < 95: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_bankruptcy_risk(bankruptcy_history):\n",
    "    return 5 if bankruptcy_history else 1\n",
    "\n",
    "def assign_previous_defaults_risk(previous_defaults):\n",
    "    if previous_defaults == 0: return 1\n",
    "    elif previous_defaults == 1: return 3\n",
    "    else: return 5\n",
    "\n",
    "def assign_utilization_risk(utilization):\n",
    "    if utilization < 0.20: return 1\n",
    "    elif 0.20 <= utilization < 0.40: return 2\n",
    "    elif 0.40 <= utilization < 0.60: return 3\n",
    "    elif 0.60 <= utilization < 0.80: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_credit_history_risk(length_of_history):\n",
    "    if length_of_history >= 10: return 1\n",
    "    elif 7 <= length_of_history < 10: return 2\n",
    "    elif 5 <= length_of_history < 7: return 3\n",
    "    elif 3 <= length_of_history < 5: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_income_risk(annual_income):\n",
    "    if annual_income >= 10800: return 1\n",
    "    elif 4200 <= annual_income < 10800: return 2\n",
    "    elif 2400 <= annual_income < 4200: return 3\n",
    "    elif 1200 <= annual_income < 2400: return 4\n",
    "    else: return 5\n",
    "\n",
    "def assign_employment_risk(employment_status):\n",
    "    if employment_status == 'Employed': return 1\n",
    "    elif employment_status == 'Self-employed': return 2\n",
    "    elif employment_status == 'Part-time': return 3\n",
    "    else: return 4  # Unemployed or other\n",
    "\n",
    "def assign_net_worth_risk(net_worth):\n",
    "    if net_worth >= 50000: return 1\n",
    "    elif 25000 <= net_worth < 50000: return 2\n",
    "    elif 10000 <= net_worth < 20000: return 3\n",
    "    elif 5000 <= net_worth < 10000: return 4\n",
    "    else: return 5\n",
    "\n",
    "# Refined overall risk calculation\n",
    "def calculate_overall_risk(row):\n",
    "    base_score = (\n",
    "        assign_credit_score_risk(row['CreditScore']) * 3 +\n",
    "        assign_dti_risk(row['DebtToIncomeRatio']) * 2 +\n",
    "        assign_payment_history_risk(row['PaymentHistory']) * 2 +\n",
    "        assign_bankruptcy_risk(row['BankruptcyHistory']) +\n",
    "        assign_previous_defaults_risk(row['PreviousLoanDefaults']) +\n",
    "        assign_utilization_risk(row['CreditCardUtilizationRate']) +\n",
    "        assign_credit_history_risk(row['LengthOfCreditHistory']) +\n",
    "        assign_income_risk(row['AnnualIncome']) * 3 +\n",
    "        assign_employment_risk(row['EmploymentStatus']) +\n",
    "        assign_net_worth_risk(row['NetWorth']) * 2\n",
    "    )\n",
    "    \n",
    "    # Adjust score based on loan approval status\n",
    "    if row['LoanApproved'] == 1:  # Assuming 1 means approved\n",
    "        base_score *= 0.8  # Reduce risk score for approved loans\n",
    "    \n",
    "    return base_score\n",
    "\n",
    "# Apply the refined risk calculation\n",
    "df['RiskScore'] = df.apply(calculate_overall_risk, axis=1)\n",
    "\n",
    "def assign_risk_level(score):\n",
    "    if score > 60:\n",
    "        return 'Low Risk'\n",
    "    elif 40 <= score <= 60:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'High Risk'\n",
    "\n",
    "# # Apply the risk level categorization\n",
    "df[' vRiskLevel'] = df['RiskScore'].apply(assign_risk_level)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('risk_level5.csv', index=False)\n",
    "print(\"\\nFocused synthetic data saved to 'focused_synthetic_loan_data.csv'\")\n",
    "\n",
    "# Display final feature count\n",
    "print(f\"\\nTotal number of features (including label): {len(df.columns)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for column in df.columns:\n",
    "    print(f\"- {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training for LoanApproved, dropping RiskScore ===\n",
      "\n",
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.94      5014\n",
      "           1       0.99      0.78      0.87      2986\n",
      "\n",
      "    accuracy                           0.91      8000\n",
      "   macro avg       0.94      0.89      0.90      8000\n",
      "weighted avg       0.92      0.91      0.91      8000\n",
      "\n",
      "Accuracy: 0.9145\n",
      "\n",
      "--- Random Forest Classifier ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.94      5014\n",
      "           1       0.98      0.78      0.87      2986\n",
      "\n",
      "    accuracy                           0.91      8000\n",
      "   macro avg       0.93      0.89      0.90      8000\n",
      "weighted avg       0.92      0.91      0.91      8000\n",
      "\n",
      "Accuracy: 0.9145\n",
      "\n",
      "--- Gradient Boosting Classifier ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.94      5014\n",
      "           1       0.99      0.78      0.87      2986\n",
      "\n",
      "    accuracy                           0.91      8000\n",
      "   macro avg       0.94      0.89      0.90      8000\n",
      "weighted avg       0.92      0.91      0.91      8000\n",
      "\n",
      "Accuracy: 0.9146\n",
      "\n",
      "=== Training for RiskScore, dropping LoanApproved ===\n",
      "\n",
      "--- Linear Regression ---\n",
      "Mean Squared Error: 20.3005\n",
      "R^2 Score: 0.7499\n",
      "\n",
      "--- Random Forest Regressor ---\n",
      "Mean Squared Error: 20.3789\n",
      "R^2 Score: 0.7489\n",
      "\n",
      "--- Gradient Boosting Regressor ---\n",
      "Mean Squared Error: 19.2706\n",
      "R^2 Score: 0.7626\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"risk_level5.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"ApplicationDate\", \"EducationLevel\", \"Experience\", \"MaritalStatus\", \"NumberOfDependents\",\n",
    "    \"HomeOwnershipStatus\", \"MonthlyDebtPayments\", \"CreditCardUtilizationRate\",\n",
    "    \"NumberOfOpenCreditLines\", \"NumberOfCreditInquiries\", \"DebtToIncomeRatio\",\n",
    "    \"BankruptcyHistory\", \"PreviousLoanDefaults\", \"PaymentHistory\", \"LengthOfCreditHistory\",\n",
    "    \"SavingsAccountBalance\", \"CheckingAccountBalance\", \"TotalAssets\", \"TotalLiabilities\",\n",
    "    \"MonthlyIncome\", \"UtilityBillsPaymentHistory\", \"JobTenure\", \"NetWorth\",\n",
    "    \"BaseInterestRate\", \"MonthlyLoanPayment\", \"TotalDebtToIncomeRatio\"\n",
    "]\n",
    "data = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Function to prepare data and train models\n",
    "def train_model(target_column, drop_column, is_regression=False):\n",
    "    print(f\"\\n=== Training for {target_column}, dropping {drop_column} ===\")\n",
    "\n",
    "    # Drop the specified column\n",
    "    data_to_train = data.drop(columns=[drop_column])\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data_to_train.drop(columns=[target_column])\n",
    "    y = data_to_train[target_column]\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Preprocessing: Handle categorical and numeric features\n",
    "    categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "    numeric_features = X.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define models based on regression or classification\n",
    "    if is_regression:\n",
    "        models = {\n",
    "            \"Linear Regression\": LinearRegression(),\n",
    "            \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "        }\n",
    "    else:\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "            \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42),\n",
    "        }\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n--- {model_name} ---\")\n",
    "        pipeline = Pipeline(steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", model),\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluation based on regression or classification\n",
    "        if is_regression:\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "            print(f\"R^2 Score: {r2:.4f}\")\n",
    "        else:\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Train for LoanApproved (classification)\n",
    "train_model(target_column=\"LoanApproved\", drop_column=\"RiskScore\", is_regression=False)\n",
    "\n",
    "# Train for RiskScore (regression)\n",
    "train_model(target_column=\"RiskScore\", drop_column=\"LoanApproved\", is_regression=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
